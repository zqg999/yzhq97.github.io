---
permalink: /
title: "About Me"
excerpt: "About me"
layout: single
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<p>
I am currently a full-time researcher at SenseTime working with Prof. <a href="http://daibo.info">Bo Dai</a> and Dr. <a href="http://wywu.github.io">Wayne Wu</a>. I obtained my Master's degree in Computer Vision at the Robotics Institute, Carnegie Mellon University, working with <a href="https://laszlojeni.com">Dr. Laszlo Jeni</a>. Prior to that, I obtained my Bachelor's degree in Software Engineering at Beihang University. I worked with Prof. <a href="http://dsd.future-lab.cn/members/qin.html">Zengchang Qin</a> and <a href="https://www.researchgate.net/profile/Yang-Yang-219">Prof. Yang Yang</a> during that time.

<!-- ## Education

2019.08 - 2020.12 **M.S. in Computer Vision**, Robotics Institute, Carnegie Mellon University  
2015.09 - 2019.06 **B.Eng in Software Engineering**, School of Software, Beihang University -->



<!-- <h3>Preprints</h3> 
<hr> -->


<h3>Publications and Projects</h3> 
<hr>


<!-- ---------------------------------------------------------- -->


<div style="width: 100%">
<div class="paper_image" style="width: 30%; display: inline-block; *display: inline; vertical-align: top;">
	<img src="/assets/mocanet/teaser.png">
</div>
<div class="paper_info" style="width: 65%; display: inline-block; *display: inline; padding-left: 1em;padding-bottom: 2em;">

<b>MoCaNet: Motion Retargeting in-the-wild via Canonicalization Networks</b>  
<br>
<small>Wentao Zhu*, <b>Zhuoqian Yang*</b>, Ziang Di, Wayne Wu, Yizhou Wang, Chen Change Loy</small>  
<br>
<small>in <b>AAAI 2022</b></small> 
<br> 
<small>* equal contribution | <a href="https://arxiv.org/abs/2112.10082">paper</a> | <a href="/mocanet">project page</a> | <a href="/assets/mocanet/poster.pdf">poster</a>
</small>

</div>
</div>

<!-- ---------------------------------------------------------- -->

<div style="width: 100%">
<div class="paper_image" style="width: 30%; display: inline-block; *display: inline; vertical-align: top;">
	<img src="/assets/transmomo/dance.gif">
</div>
<div class="paper_info" style="width: 65%; display: inline-block; *display: inline; padding-left: 1em;padding-bottom: 2em;">

<b>TransMoMo: Invariance-Driven Unsupervised Video Motion Retargeting</b>  
<br>
<small><b>Zhuoqian Yang*</b>, Wentao Zhu*, Wayne Wu*, Chen Qian, Qiang Zhou, Bolei Zhou, Chen Change Loy</small>  
<br>
<small>in <b>CVPR 2020</b></small> 
<br> 
<small>* equal contribution | <a href="https://arxiv.org/abs/2003.14401">paper</a> | <a href="/transmomo">project page</a> | <a href="https://github.com/yzhq97/transmomo.pytorch">code</a>
</small>

</div>
</div>

<!-- ---------------------------------------------------------- -->

<div style="width: 100%">
<div class="paper_image" style="width: 30%; display: inline-block; *display: inline; vertical-align: top;">
	<img src="/assets/images/sfim.png">
</div>
<div class="paper_info" style="width: 65%; display: inline-block; *display: inline; padding-left: 1em;padding-bottom: 2em;">

<b>Semantic Facial Image Manipulation using 2D/3D modalities</b>  
<br>
<small><b>Zhuoqian Yang</b>, Dai Li, Koichiro Niinuma, Laszlo Jeni</small>  
<br>
<small style="color:#8b0000;"><b>CMU </b></small><small><b>MSCV Capstone Project</b></small> 
<br>
<small>Sponsor: Fujitsu Research of America</small>
<small><a href="https://mscvprojects.ri.cmu.edu/2020teaml/">project page</a> | <a href="https://drive.google.com/file/d/1UbTcLudyGlr4OiP10rQ53OjattXGkA5B/view?usp=sharing">slides</a>
</small>

</div>
</div>

<!-- ---------------------------------------------------------- -->

<div style="width: 100%">
<div class="paper_image" style="width: 30%; display: inline-block; *display: inline; vertical-align: top;">
	<img src="/assets/images/mead.jpg">
</div>
<div class="paper_info" style="width: 65%; display: inline-block; *display: inline; padding-left: 1em;padding-bottom: 2em;">

<b>MEAD: A Large-scale Audio-visual Dataset for Emotional Talking-face Generation</b>  
<br>
<small>Kaisiyuan Wang*, Qianyi Wu*, Linsen Song*, <b>Zhuoqian Yang</b>, Wayne Wu, Chen Qian, Ran He, Yu Qiao, Chen Change Loy</small>  
<br>
<small>in <b>ECCV 2020</b></small>
<br> 
<small>* equal contribution | <a href="http://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123660698.pdf">paper</a> | <a href="https://wywu.github.io/projects/MEAD/MEAD.html">project page</a> 
</small>

</div>
</div>

<!-- ---------------------------------------------------------- -->

<div style="width: 100%">

<div class="paper_image" style="width: 30%; display: inline-block; *display: inline; vertical-align: top;">
	<img src="/assets/images/nonrigid.png">
</div>

<div class="paper_info" style="width: 65%; display: inline-block; *display: inline; padding-left: 1em;padding-bottom: 2em;">

<b>Non-rigid Image Registration with Dynamic Gaussian Component Density and Space Curvature Preservation</b> 
<br>
<small><b>Zhuoqian Yang</b>, Yang Yang, Kun Yang, Ziquan Wei</small>  
<br>
<small><b>IEEE Transactions on Image Processing</b>, 28(5), 2584-2598</small>  
<br>
<small><a href="https://doi.org/10.1109/TIP.2018.2887204">paper</a></small>

</div>
</div>

<!-- ---------------------------------------------------------- -->

<div style="width: 100%">
<div class="paper_image" style="width: 30%; display: inline-block; *display: inline; vertical-align: top;">
	<img src="/assets/images/scenegcn.png">
</div>
<div class="paper_info" style="width: 65%; display: inline-block; *display: inline; padding-left: 1em;padding-bottom: 2em;">

<b>Scene Graph Reasoning with Prior Visual Relationship for Visual Question Answering</b>  
<br>
<small><b>Zhuoqian Yang</b>, Zengchang Qin, Jing Yu, Yue Hu</small> 
<br>
<small>in <b>ICIP 2020</b></small> 
<br>
<small><a href="https://arxiv.org/abs/1812.09681">paper</a></small>

</div>
</div>

<!-- ---------------------------------------------------------- -->

<div style="width: 100%">
<div class="paper_image" style="width: 30%; display: inline-block; *display: inline; vertical-align: top;">
	<img src="/assets/images/cnnreg.png">
</div>
<div class="paper_info" style="width: 65%; display: inline-block; *display: inline; padding-left: 1em;padding-bottom: 2em;">

<b>Multi-Temporal Remote Sensing Image Registration Using Deep Convolutional Features</b>  
<br>
<small><b>Zhuoqian Yang</b>, Tingting Dan, Yang Yang</small>
<br>
<small><b>IEEE Access</b>, vol.~6, pp.~38544--38555</small>  
<br>
<small><a href="https://doi.org/10.1109/ACCESS.2018.2853100">paper</a> | <a href="https://github.com/yzhq97/cnn-registration.git">code</a></small>

</div>
</div>

